# OpenShift AI 2.22 - Configuration GitOps COMPLETE ğŸš€

Configuration GitOps complÃ¨te pour **OpenShift AI 2.22** avec **toutes les fonctionnalitÃ©s officielles** documentÃ©es.

## ğŸ¯ FonctionnalitÃ©s Incluses

### ğŸ”§ Composants Core OpenShift AI
- âœ… **Data Science Dashboard** - Interface principale
- âœ… **Jupyter Workbenches** - Environnements de dÃ©veloppement
- âœ… **Model Serving** - KServe + ModelMesh
- âœ… **Data Science Pipelines** - Kubeflow Pipelines
- âœ… **Distributed Workloads** - CodeFlare + Ray
- âœ… **Model Registry** - Gestion des modÃ¨les ML

### ğŸ¯ FonctionnalitÃ©s AvancÃ©es 2.22
- âœ… **TrustyAI** - Explainable AI et monitoring
- âœ… **Training Operator** - PyTorch, TensorFlow, XGBoost, MPI
- âœ… **Kueue** - Job queueing et resource management
- âœ… **Service Mesh** - Istio pour sÃ©curitÃ© et observabilitÃ©
- âœ… **Serverless** - Knative pour scaling automatique

### ğŸ‘¥ Gestion des Utilisateurs
- Configuration HTPasswd intelligente
- PrÃ©servation automatique de l'utilisateur actuel
- Utilisateurs prÃ©-configurÃ©s pour tests
- Roles RBAC optimisÃ©s
- **Workbenches** : Jupyter notebooks avec GPU support
- **Model Serving** : KServe et ModelMesh
- **Data Science Pipelines** : MLOps avec Tekton
- **TrustyAI** : Explainability et bias detection

### ğŸ§ª Technology Preview (2.22)
- **Model Registry v2.x** : Registry centralisÃ© avec UI amÃ©liorÃ©e
- **Feature Store** : Stockage centralisÃ© des features
- **LAB-tuning** : Fine-tuning de large language models
- **Distributed Workloads** : Orchestration avancÃ©e avec Kueue

### â˜ï¸ Infrastructure ComplÃ¨te
- **S3 Storage** : MinIO pour artifacts et datasets
- **Database** : MySQL pour Model Registry
- **Service Mesh** : Istio pour sÃ©curitÃ© mTLS
- **Monitoring** : Prometheus + Grafana + alertes

### ğŸ‘¥ Gestion Utilisateurs
- **OAuth HTPasswd** : Authentification intÃ©grÃ©e
- **RBAC** : Permissions granulaires par rÃ´le
- **Groupes** : data-scientists, data-engineers, mlops-engineers
- **Projects** : Isolation par utilisateur avec quotas

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     OpenShift AI 2.22                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 1: Prerequisites                                      â”‚
â”‚ â”œâ”€ Service Mesh Operator                                    â”‚
â”‚ â”œâ”€ Serverless Operator                                      â”‚
â”‚ â”œâ”€ Pipelines Operator                                       â”‚
â”‚ â”œâ”€ OpenShift AI Operator                                    â”‚
â”‚ â””â”€ OpenShift GitOps Operator (ArgoCD)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 2: Core AI Platform                                  â”‚
â”‚ â”œâ”€ DataScienceClusterInitialization (DSCI)                 â”‚
â”‚ â”œâ”€ DataScienceCluster (DSC)                                â”‚
â”‚ â”œâ”€ Dashboard + Workbenches                                  â”‚
â”‚ â”œâ”€ KServe + ModelMesh Serving                              â”‚
â”‚ â”œâ”€ Data Science Pipelines                                  â”‚
â”‚ â”œâ”€ TrustyAI + CodeFlare + Ray                              â”‚
â”‚ â””â”€ Model Registry (Tech Preview)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 3: Advanced Components                               â”‚
â”‚ â”œâ”€ Service Mesh Control Plane                              â”‚
â”‚ â”œâ”€ Knative Serving + Eventing                              â”‚
â”‚ â”œâ”€ Model Registry v2 Configuration                         â”‚
â”‚ â””â”€ Monitoring + Alerting                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 4: Storage & Infrastructure                          â”‚
â”‚ â”œâ”€ MinIO S3 (model artifacts, datasets)                    â”‚
â”‚ â”œâ”€ MySQL (Model Registry database)                         â”‚
â”‚ â”œâ”€ PVCs + StorageClasses                                   â”‚
â”‚ â””â”€ Backup + Restore Jobs                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 5: Users & RBAC                                      â”‚
â”‚ â”œâ”€ OAuth HTPasswd Provider                                 â”‚
â”‚ â”œâ”€ Users + Groups                                          â”‚
â”‚ â”œâ”€ RBAC Bindings                                           â”‚
â”‚ â””â”€ NetworkPolicies                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Installation GitOps (RecommandÃ©e)

### Quick Start
```bash
# Cloner le repository
git clone <repo-url>
cd openshift-ai-setup

# DÃ©ploiement complet automatique
make gitops-deploy

# Ou dÃ©ploiement phase par phase
make gitops-deploy-phase PHASE=1
make gitops-deploy-phase PHASE=2
make gitops-deploy-phase PHASE=3
make gitops-deploy-phase PHASE=4
make gitops-deploy-phase PHASE=5
```

### Installation dÃ©taillÃ©e

1. **VÃ©rifier les prÃ©requis**
```bash
# VÃ©rifier la connexion au cluster
oc whoami
oc version

# VÃ©rifier les permissions (cluster-admin requis)
oc auth can-i create clusterroles
```

2. **Simulation (recommandÃ©e)**
```bash
# Tester sans dÃ©ployer
make gitops-dry-run
```

3. **DÃ©ploiement complet**
```bash
# DÃ©ploiement automatique avec monitoring
./deploy-openshift-ai.sh

# Ou via Makefile
make gitops-deploy
```

4. **VÃ©rification du dÃ©ploiement**
```bash
# Status global
make gitops-status

# Status dÃ©taillÃ© des composants
oc get dsc,dsci -o wide
oc get pods -A | grep -E "(rhods|minio|mysql)"
```

## ğŸ“Š AccÃ¨s aux Services

Une fois le dÃ©ploiement terminÃ© :

### ğŸŒ OpenShift AI Dashboard
```bash
# Obtenir l'URL
oc get route rhods-dashboard -n redhat-ods-applications -o jsonpath='{.spec.host}'

# AccÃ¨s: https://<dashboard-url>
# Utilisateurs par dÃ©faut:
# - admin / openshift123 (cluster admin)
# - rhods-admin / openshift123 (OpenShift AI admin)
# - datascientist1 / openshift123 (data scientist)
# - datascientist2 / openshift123 (data scientist)
# - dataengineer1 / openshift123 (data engineer)
# - mlops1 / openshift123 (MLOps engineer)
```

### ğŸ—„ï¸ MinIO S3 Console
```bash
# Obtenir l'URL
oc get route minio-console -n minio -o jsonpath='{.spec.host}'

# AccÃ¨s: https://<minio-url>
# Username: admin
# Password: password123
```

### ğŸ“ˆ Monitoring
```bash
# Prometheus
oc get route prometheus -n redhat-ods-monitoring

# Grafana
oc get route grafana-route -n redhat-ods-monitoring
```

## ğŸ§ª Technology Preview Features

### Model Registry v2.x
```bash
# AccÃ©der via Dashboard > Settings > Model registry settings
# Ou directement:
oc get route model-registry -n model-registry
```

### LAB-tuning (Large Model Tuning)
```bash
# VÃ©rifier si disponible
oc get pods -n redhat-ods-applications | grep lab-tuning

# AccÃ¨s via Dashboard > Distributed workloads
```

### Distributed Workloads
```bash
# VÃ©rifier Kueue operator
oc get pods -n kueue-system

# CrÃ©er des Ray clusters via Dashboard
```

## ğŸ“ Structure du projet

```
â”œâ”€â”€ gitops/                        # ğŸš€ GitOps dÃ©ploiement OpenShift AI 2.22
â”‚   â”œâ”€â”€ README.md                  # Documentation GitOps complÃ¨te
â”‚   â”œâ”€â”€ phase-01-prerequisites/    # Operators (Service Mesh, Serverless, etc.)
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â”œâ”€â”€ namespaces.yaml
â”‚   â”‚   â”œâ”€â”€ operator-groups.yaml
â”‚   â”‚   â””â”€â”€ subscriptions.yaml
â”‚   â”œâ”€â”€ phase-02-openshift-ai-core/ # DSCI, DSC, composants principaux
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â”œâ”€â”€ dsci.yaml
â”‚   â”‚   â””â”€â”€ dsc.yaml
â”‚   â”œâ”€â”€ phase-03-advanced-components/ # Service Mesh CP, Knative, Model Registry
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â”œâ”€â”€ service-mesh-control-plane.yaml
â”‚   â”‚   â”œâ”€â”€ knative-serving.yaml
â”‚   â”‚   â”œâ”€â”€ knative-eventing.yaml
â”‚   â”‚   â””â”€â”€ monitoring-config.yaml
â”‚   â”œâ”€â”€ phase-04-storage-and-infrastructure/ # MinIO, MySQL, PVCs, backups
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â”œâ”€â”€ namespaces.yaml
â”‚   â”‚   â”œâ”€â”€ minio-deployment.yaml
â”‚   â”‚   â”œâ”€â”€ mysql-deployment.yaml
â”‚   â”‚   â”œâ”€â”€ storage-configs.yaml
â”‚   â”‚   â””â”€â”€ backup-configs.yaml
â”‚   â””â”€â”€ phase-05-users-and-rbac/   # OAuth, utilisateurs, permissions
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ kustomization.yaml
â”‚       â”œâ”€â”€ oauth-provider.yaml
â”‚       â”œâ”€â”€ users-groups.yaml
â”‚       â””â”€â”€ rbac-bindings.yaml
â”œâ”€â”€ deploy-openshift-ai.sh         # ğŸš€ Script de dÃ©ploiement automatique
â”œâ”€â”€ Makefile                       # Commands GitOps intÃ©grÃ©es
â”œâ”€â”€ package.json                   # MÃ©tadonnÃ©es du projet
â””â”€â”€ README.md                      # Documentation principale
```

## ğŸ‘¥ Utilisateurs crÃ©Ã©s par dÃ©faut

| Utilisateur | RÃ´le | Permissions | Mot de passe |
|-------------|------|-------------|--------------|
| `admin` | Super Admin | `cluster-admin` complet | `openshift123` |
| `mouachan` | Cluster Admin | `cluster-admin` complet | `openshift123` |
| `rhods-admin` | Admin OpenShift AI | Admin OpenShift AI | `openshift123` |
| `datascientist1` | Data Scientist | Workbenches + Model Serving | `openshift123` |
| `datascientist2` | Data Scientist | Workbenches + Pipelines | `openshift123` |
| `dataengineer1` | Data Engineer | Infrastructure + Storage | `openshift123` |
| `mlops1` | MLOps Engineer | Monitoring + Deployment | `openshift123` |

âš ï¸ **Production** : Changez tous les mots de passe par dÃ©faut !

## ğŸ”§ Services dÃ©ployÃ©s automatiquement

### ğŸŒ OpenShift AI Core
- **Dashboard** : Interface web principale
- **Workbenches** : Jupyter notebooks avec GPU support
- **Model Serving** : KServe + ModelMesh auto-scaling
- **Data Science Pipelines** : MLOps avec Tekton
- **TrustyAI** : Explainability et bias detection
- **CodeFlare + Ray** : Distributed computing

### ğŸ§ª Technology Preview (2.22)
- **Model Registry v2.x** : Registry centralisÃ© avec UI amÃ©liorÃ©e
- **Distributed Workloads** : Orchestration avec Kueue
- **LAB-tuning** : Fine-tuning de Large Language Models
- **Feature Store** : Stockage centralisÃ© des features

### ğŸ—„ï¸ Infrastructure
- **MinIO S3** : Stockage compatible S3 (buckets: model-artifacts, datasets, pipelines, notebooks)
- **MySQL** : Base de donnÃ©es Model Registry avec backup automatique
- **Service Mesh** : Istio Control Plane avec mTLS
- **Monitoring** : Prometheus + Grafana + alertes personnalisÃ©es

## ğŸ“š Documentation

- [ğŸ“‹ GitOps Guide Complet](gitops/README.md) - Documentation principale GitOps
- [ğŸ”§ Phase 1: Prerequisites](gitops/phase-01-prerequisites/README.md) - Service Mesh, Serverless, Pipelines
- [ğŸ¤– Phase 2: Core AI Platform](gitops/phase-02-openshift-ai-core/README.md) - DSCI, DSC, composants
- [ğŸš€ Phase 3: Advanced Components](gitops/phase-03-advanced-components/README.md) - Service Mesh CP, Model Registry
- [ğŸ—„ï¸ Phase 4: Storage & Infrastructure](gitops/phase-04-storage-and-infrastructure/README.md) - MinIO, MySQL, backups
- [ğŸ‘¥ Phase 5: Users & RBAC](gitops/phase-05-users-and-rbac/README.md) - OAuth, utilisateurs, permissions

## ğŸ› ï¸ Commandes GitOps

```bash
# ğŸš€ DÃ©ploiement complet automatique
make gitops-deploy

# ğŸ” Simulation avant dÃ©ploiement
make gitops-dry-run

# ğŸ“Š Status de tous les composants
make gitops-status

# ğŸ—ï¸ DÃ©ploiement phase par phase
make gitops-deploy-phase PHASE=1  # Prerequisites
make gitops-deploy-phase PHASE=2  # OpenShift AI Core
make gitops-deploy-phase PHASE=3  # Advanced Components
make gitops-deploy-phase PHASE=4  # Storage & Infrastructure
make gitops-deploy-phase PHASE=5  # Users & RBAC

# ğŸ“š Documentation GitOps
make gitops-docs

# ğŸ§¹ Nettoyage complet (avec confirmation)
make gitops-clean
```

### Commandes legacy (maintenues pour compatibilitÃ©)
```bash
# VÃ©rifier le statut gÃ©nÃ©ral
make status

# Tests utilisateurs (si configurÃ©s manuellement)
make test-users

# Nettoyer anciennes ressources
make clean

# Obtenir l'URL du dashboard
make dashboard-url
```

## âœ… PrÃ©requis

- **Cluster OpenShift 4.12+** accessible
- **Permissions `cluster-admin`** requises
- **CLI `oc`** installÃ© et configurÃ©
- **Connexion internet** pour tÃ©lÃ©charger les images
- **Ressources cluster** : 16+ vCPU, 32+ GB RAM, 500+ GB storage
- **StorageClass** par dÃ©faut configurÃ©e (ex: gp3-csi, fast-ssd)

## ğŸ”’ SÃ©curitÃ© intÃ©grÃ©e

- âœ… **TLS/HTTPS** sur toutes les routes externes
- âœ… **Service Mesh mTLS** entre composants internes
- âœ… **NetworkPolicies** pour isolation rÃ©seau
- âœ… **RBAC granulaire** par rÃ´les et namespaces
- âœ… **Secrets** chiffrÃ©s pour credentials
- âœ… **OAuth HTPasswd** provider sÃ©curisÃ©
- âœ… **Backup automatique** des donnÃ©es critiques

## ğŸ¤ Contribution

1. Fork du projet
2. CrÃ©er une branche pour votre fonctionnalitÃ©
3. Commit de vos changements
4. Push vers la branche
5. Ouvrir une Pull Request

## ğŸ“ Licence

MIT License - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ†˜ Support

- Consultez la [documentation complÃ¨te](docs/installation-guide.md)
- Ouvrez une issue sur GitHub pour les bugs
- Consultez les logs avec `oc logs` en cas de problÃ¨me
