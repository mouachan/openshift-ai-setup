# OpenShift AI 2.22 - D√©ploiement GitOps avec Kustomize

Ce projet suit la structure et les bonnes pratiques du repository [rh-aiservices-bu/rhoaibu-cluster](https://github.com/rh-aiservices-bu/rhoaibu-cluster) avec une approche 100% GitOps utilisant Kustomize.

## üèóÔ∏è Structure du Projet

```
clusters/
  overlays/
    openshift-ai-dev/          # Point d'entr√©e principal pour environnement dev
      kustomization.yaml       # Configuration principale Kustomize
      dev-patches.yaml         # Patches sp√©cifiques dev

components/
  operators/                   # Op√©rateurs avec structure base/overlays
    openshift-gitops-operator/
      base/
        kustomization.yaml
        subscription.yaml
      kustomization.yaml
    openshift-service-mesh/
    kiali-operator/
    openshift-serverless-operator/
    openshift-pipelines-operator/
    rhoai-operator/             # OpenShift AI 2.22 (stable-2.22)
    
  instances/                   # Instances avec structure base/overlays
    service-mesh-instance/
      base/
        kustomization.yaml
        control-plane.yaml      # ServiceMeshControlPlane v2.5
      kustomization.yaml
    serverless-instance/
      base/
        kustomization.yaml
        knative.yaml           # KnativeServing + KnativeEventing
      kustomization.yaml
    pipelines-instance/
      base/
        kustomization.yaml
        pipelines-instance.yaml # TektonConfig avec int√©gration DS
      kustomization.yaml
    rhoai-instance/
      base/
        kustomization.yaml
        rhoai.yaml             # DSCInitialization + DataScienceCluster
      kustomization.yaml
```

## üöÄ D√©ploiement

### Option 1: D√©ploiement Complet (Recommand√©)

```bash
# D√©ployer toute la stack OpenShift AI 2.22
kubectl apply -k clusters/overlays/openshift-ai-dev
```

### Option 2: D√©ploiement par √âtapes

```bash
# 1. D√©ployer les op√©rateurs (dans l'ordre)
kubectl apply -k components/operators/openshift-gitops-operator
kubectl apply -k components/operators/openshift-service-mesh  
kubectl apply -k components/operators/kiali-operator
kubectl apply -k components/operators/openshift-serverless-operator
kubectl apply -k components/operators/openshift-pipelines-operator
kubectl apply -k components/operators/rhoai-operator

# 2. Attendre que les op√©rateurs soient pr√™ts
kubectl wait --for=condition=Ready pod -l name=servicemeshoperator -n openshift-operators --timeout=300s

# 3. D√©ployer les instances
kubectl apply -k components/instances/service-mesh-instance
kubectl apply -k components/instances/serverless-instance  
kubectl apply -k components/instances/pipelines-instance
kubectl apply -k components/instances/rhoai-instance
```

## üîç V√©rification du D√©ploiement

```bash
# V√©rifier les op√©rateurs
kubectl get subscription -A | grep -E "(servicemesh|serverless|pipelines|rhods)"

# V√©rifier Service Mesh
kubectl get servicemeshcontrolplane -n istio-system

# V√©rifier Serverless  
kubectl get knativeserving -n knative-serving
kubectl get knativeeventing -n knative-eventing

# V√©rifier Pipelines
kubectl get tektonconfig -n openshift-pipelines

# V√©rifier OpenShift AI 2.22
kubectl get datasciencecluster,dscinitialization -A
```

## üéØ Composants D√©ploy√©s

### OpenShift AI 2.22
- **Canal**: `stable-2.22` (version fixe)
- **Composants**: Dashboard, Workbenches, Data Science Pipelines, KServe, CodeFlare, Kueue, ModelMesh, Ray, TrustyAI, Model Registry

### Service Mesh v2.5
- **Addons**: Jaeger, Kiali, Grafana
- **S√©curit√©**: mTLS automatique activ√©
- **Monitoring**: Int√©gr√© pour RHOAI

### Serverless
- **Ingress**: Istio Gateway int√©gr√©
- **Certificats**: Workload certificates activ√©s
- **KServe**: Support complet pour model serving

### Pipelines
- **Version**: Latest stable
- **Int√©grations**: Hub Tekton, Pipelines as Code
- **ML Support**: Optimis√© pour data science workflows

## üõ†Ô∏è Personnalisation

### Modifier la Configuration

1. **Environnement de d√©veloppement**: √âditer `clusters/overlays/openshift-ai-dev/dev-patches.yaml`
2. **Base operators**: Modifier les fichiers dans `components/operators/*/base/`  
3. **Base instances**: Modifier les fichiers dans `components/instances/*/base/`

### Cr√©er un Nouvel Environnement

```bash
mkdir -p clusters/overlays/openshift-ai-prod
cp clusters/overlays/openshift-ai-dev/kustomization.yaml clusters/overlays/openshift-ai-prod/
# Modifier le kustomization.yaml pour production
```

## üè∑Ô∏è Conformit√© rh-aiservices-bu

Ce projet suit exactement la m√™me structure que le repository de r√©f√©rence:
- ‚úÖ Structure `base/` et `overlays/` avec Kustomize
- ‚úÖ S√©paration `operators/` et `instances/`  
- ‚úÖ Point d'entr√©e `clusters/overlays/<ENVIRONMENT>`
- ‚úÖ Patches environnement-sp√©cifiques
- ‚úÖ GitOps pur sans scripts shell
- ‚úÖ OpenShift AI 2.22 avec canal stable-2.22

## üìù Notes

- Les erreurs de lint VS Code sont normales (CRDs OpenShift non reconnus)
- L'ordre de d√©ploiement est important (operators ‚Üí instances)  
- Service Mesh doit √™tre pr√™t avant KServe
- Compatible ArgoCD Applications pour automatisation compl√®te
