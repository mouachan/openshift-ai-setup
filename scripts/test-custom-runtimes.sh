#!/bin/bash
# Test des custom serving runtimes Triton et Seldon
# V√©rification post-d√©ploiement GitOps

echo "üß™ Test des Custom Serving Runtimes OpenShift AI 2.22"
echo "====================================================="

# Couleurs pour l'output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

TOTAL_TESTS=0
PASSED_TESTS=0

test_result() {
    TOTAL_TESTS=$((TOTAL_TESTS + 1))
    if [ $1 -eq 0 ]; then
        echo -e "${GREEN}‚úÖ PASS${NC}: $2"
        PASSED_TESTS=$((PASSED_TESTS + 1))
    else
        echo -e "${RED}‚ùå FAIL${NC}: $2"
    fi
}

echo "üîç Test 1: Application ArgoCD synchronis√©e"
APP_SYNC=$(oc get applications.argoproj.io openshift-ai-complete -n openshift-gitops -o jsonpath='{.status.sync.status}' 2>/dev/null)
[ "$APP_SYNC" = "Synced" ]
test_result $? "Application ArgoCD synchronis√©e ($APP_SYNC)"

echo ""
echo "üîç Test 2: Templates install√©s"

# Test Template NVIDIA Triton
oc get template nvidia-triton-runtime-template -n redhat-ods-applications >/dev/null 2>&1
test_result $? "Template NVIDIA Triton pr√©sent"

# Test Template Seldon MLServer
oc get template seldon-mlserver-template -n redhat-ods-applications >/dev/null 2>&1
test_result $? "Template Seldon MLServer pr√©sent"

echo ""
echo "üîç Test 3: Serving Runtimes install√©s"

# Test NVIDIA Triton Runtime
oc get servingruntime triton-runtime -n redhat-ods-applications >/dev/null 2>&1
test_result $? "NVIDIA Triton Runtime pr√©sent"

# Test Seldon MLServer Runtime  
oc get servingruntime seldon-mlserver-runtime -n redhat-ods-applications >/dev/null 2>&1
test_result $? "Seldon MLServer Runtime pr√©sent"

echo ""
echo "üîç Test 4: Configuration des runtimes"

# V√©rifier les formats support√©s par Triton
TRITON_FORMATS=$(oc get servingruntime triton-runtime -n redhat-ods-applications -o jsonpath='{.spec.supportedModelFormats[*].name}' 2>/dev/null)
echo "$TRITON_FORMATS" | grep -q "tensorflow" && echo "$TRITON_FORMATS" | grep -q "pytorch" && echo "$TRITON_FORMATS" | grep -q "onnx"
test_result $? "Triton supporte TensorFlow, PyTorch, ONNX ($TRITON_FORMATS)"

# V√©rifier les formats support√©s par Seldon
SELDON_FORMATS=$(oc get servingruntime seldon-mlserver-runtime -n redhat-ods-applications -o jsonpath='{.spec.supportedModelFormats[*].name}' 2>/dev/null)
echo "$SELDON_FORMATS" | grep -q "sklearn" && echo "$SELDON_FORMATS" | grep -q "xgboost" && echo "$SELDON_FORMATS" | grep -q "mlflow"
test_result $? "Seldon supporte sklearn, XGBoost, MLflow ($SELDON_FORMATS)"

echo ""
echo "üîç Test 5: Configuration Prometheus"

# V√©rifier les annotations Prometheus Triton
TRITON_PROMETHEUS=$(oc get servingruntime triton-runtime -n redhat-ods-applications -o jsonpath='{.spec.annotations}' 2>/dev/null)
echo "$TRITON_PROMETHEUS" | grep -q "prometheus.kserve.io"
test_result $? "Triton - Annotations Prometheus configur√©es"

# V√©rifier les annotations Prometheus Seldon
SELDON_PROMETHEUS=$(oc get servingruntime seldon-mlserver-runtime -n redhat-ods-applications -o jsonpath='{.spec.annotations}' 2>/dev/null)
echo "$SELDON_PROMETHEUS" | grep -q "prometheus.kserve.io"
test_result $? "Seldon - Annotations Prometheus configur√©es"

echo ""
echo "üîç Test 6: Configuration multi-model"

# V√©rifier multi-model pour Triton
TRITON_MULTIMODEL=$(oc get servingruntime triton-runtime -n redhat-ods-applications -o jsonpath='{.spec.multiModel}' 2>/dev/null)
[ "$TRITON_MULTIMODEL" = "true" ]
test_result $? "Triton - Multi-model support√© ($TRITON_MULTIMODEL)"

# V√©rifier multi-model pour Seldon  
SELDON_MULTIMODEL=$(oc get servingruntime seldon-mlserver-runtime -n redhat-ods-applications -o jsonpath='{.spec.multiModel}' 2>/dev/null)
[ "$SELDON_MULTIMODEL" = "true" ]
test_result $? "Seldon - Multi-model support√© ($SELDON_MULTIMODEL)"

echo ""
echo "üîç Test 8: Configuration pour l'interface dashboard"

# V√©rifier les annotations d'affichage Triton
TRITON_DASHBOARD=$(oc get servingruntime triton-runtime -n redhat-ods-applications -o jsonpath='{.metadata.labels.opendatahub\.io/dashboard}' 2>/dev/null)
[ "$TRITON_DASHBOARD" = "true" ]
test_result $? "Triton - Label dashboard configur√© ($TRITON_DASHBOARD)"

TRITON_DISPLAY=$(oc get servingruntime triton-runtime -n redhat-ods-applications -o jsonpath='{.metadata.annotations.openshift\.io/display-name}' 2>/dev/null)
[ "$TRITON_DISPLAY" = "NVIDIA Triton Inference Server" ]
test_result $? "Triton - Nom d'affichage configur√© ($TRITON_DISPLAY)"

# V√©rifier les annotations d'affichage Seldon
SELDON_DASHBOARD=$(oc get servingruntime seldon-mlserver-runtime -n redhat-ods-applications -o jsonpath='{.metadata.labels.opendatahub\.io/dashboard}' 2>/dev/null)
[ "$SELDON_DASHBOARD" = "true" ]
test_result $? "Seldon - Label dashboard configur√© ($SELDON_DASHBOARD)"

SELDON_DISPLAY=$(oc get servingruntime seldon-mlserver-runtime -n redhat-ods-applications -o jsonpath='{.metadata.annotations.openshift\.io/display-name}' 2>/dev/null)
[ "$SELDON_DISPLAY" = "Seldon MLServer" ]
test_result $? "Seldon - Nom d'affichage configur√© ($SELDON_DISPLAY)"

echo ""
echo "üîç Test 7: V√©rification des images"

# V√©rifier l'image Triton
TRITON_IMAGE=$(oc get servingruntime triton-runtime -n redhat-ods-applications -o jsonpath='{.spec.containers[0].image}' 2>/dev/null)
echo "$TRITON_IMAGE" | grep -q "nvcr.io/nvidia/tritonserver"
test_result $? "Triton - Image officielle NVIDIA ($TRITON_IMAGE)"

# V√©rifier l'image Seldon
SELDON_IMAGE=$(oc get servingruntime seldon-mlserver-runtime -n redhat-ods-applications -o jsonpath='{.spec.containers[0].image}' 2>/dev/null)
echo "$SELDON_IMAGE" | grep -q "seldonio/mlserver"
test_result $? "Seldon - Image officielle Seldon ($SELDON_IMAGE)"

echo ""
echo "================================================="
echo "üìä R√âSULTATS DES TESTS"
echo "================================================="
echo -e "Total: $TOTAL_TESTS tests"
echo -e "${GREEN}R√©ussis: $PASSED_TESTS${NC}"
echo -e "${RED}√âchou√©s: $((TOTAL_TESTS - PASSED_TESTS))${NC}"

if [ $PASSED_TESTS -eq $TOTAL_TESTS ]; then
    echo -e "\nüéâ ${GREEN}TOUS LES TESTS R√âUSSIS !${NC}"
    echo ""
    echo -e "${BLUE}üìã Runtimes disponibles :${NC}"
    echo "  ‚Ä¢ NVIDIA Triton (TensorFlow, PyTorch, ONNX, TensorRT)"
    echo "  ‚Ä¢ Seldon MLServer (scikit-learn, XGBoost, MLflow, Hugging Face)"
    echo ""
    echo -e "${BLUE}üöÄ Utilisation :${NC}"
    echo "  1. OpenShift AI Dashboard ‚Üí Model Serving"
    echo "  2. Deploy model ‚Üí S√©lectionner runtime appropri√©"
    echo "  3. Configurer mod√®le selon format support√©"
    echo ""
    echo -e "${BLUE}üìä Monitoring :${NC}"
    echo "  ‚Ä¢ Triton metrics: http://<service>:8002/metrics"
    echo "  ‚Ä¢ Seldon metrics: http://<service>:8080/metrics"
    exit 0
else
    echo -e "\n‚ö†Ô∏è  ${YELLOW}CERTAINS TESTS ONT √âCHOU√â${NC}"
    echo "V√©rifiez la synchronisation ArgoCD et les logs des pods."
    exit 1
fi
