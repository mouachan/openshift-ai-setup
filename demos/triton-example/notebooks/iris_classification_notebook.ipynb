{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ï¿½ï¿½ Classification Iris avec Triton Inference Server\n",
        "\n",
        "Ce notebook dÃ©montre l'utilisation de NVIDIA Triton Inference Server pour dÃ©ployer et servir un modÃ¨le de classification Iris.\n",
        "\n",
        "## Configuration de l'environnement\n",
        "- **Image**: `s2i-generic-data-science-notebook:2025.1`\n",
        "- **Namespace**: `triton-demo`\n",
        "- **User**: `mouachan`\n",
        "- **Base URL**: `/notebook/triton-demo/test-triton`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Configuration de l'environnement...\n",
            "ğŸ“ RÃ©pertoire de travail: /Users/mouchan/projects/openshift-ai-setup/demos/triton-example/notebooks\n",
            "ğŸ‘¤ Utilisateur: mouchan\n",
            "ğŸ·ï¸ Namespace: unknown\n",
            "\n",
            "ğŸ”— Configuration du workbench:\n",
            "   JUPYTER_IMAGE: Non configurÃ©\n",
            "\n",
            "ğŸ“Š Configuration Model Registry:\n",
            "   MODEL_REGISTRY_URL: Non configurÃ©\n",
            "\n",
            "â˜ï¸ Configuration S3/MinIO:\n",
            "   AWS_ACCESS_KEY_ID: Non configurÃ©\n",
            "   AWS_S3_ENDPOINT: Non configurÃ©\n",
            "   AWS_S3_BUCKET: Non configurÃ©\n",
            "\n",
            "âœ… Dossiers crÃ©Ã©s\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"ğŸ”§ Configuration de l'environnement...\")\n",
        "print(f\"ğŸ“ RÃ©pertoire de travail: {os.getcwd()}\")\n",
        "print(f\"ğŸ‘¤ Utilisateur: {os.getenv('USER', 'unknown')}\")\n",
        "print(f\"ğŸ·ï¸ Namespace: {os.getenv('NAMESPACE', 'unknown')}\")\n",
        "\n",
        "# Variables d'environnement du workbench\n",
        "print(f\"\\nğŸ”— Configuration du workbench:\")\n",
        "print(f\"   JUPYTER_IMAGE: {os.getenv('JUPYTER_IMAGE', 'Non configurÃ©')}\")\n",
        "\n",
        "# Variables Model Registry et S3\n",
        "print(f\"\\nğŸ“Š Configuration Model Registry:\")\n",
        "print(f\"   MODEL_REGISTRY_URL: {os.getenv('MODEL_REGISTRY_URL', 'Non configurÃ©')}\")\n",
        "\n",
        "print(f\"\\nâ˜ï¸ Configuration S3/MinIO:\")\n",
        "print(f\"   AWS_ACCESS_KEY_ID: {os.getenv('AWS_ACCESS_KEY_ID', 'Non configurÃ©')}\")\n",
        "print(f\"   AWS_S3_ENDPOINT: {os.getenv('AWS_S3_ENDPOINT', 'Non configurÃ©')}\")\n",
        "print(f\"   AWS_S3_BUCKET: {os.getenv('AWS_S3_BUCKET', 'Non configurÃ©')}\")\n",
        "\n",
        "# CrÃ©er les dossiers nÃ©cessaires\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('data', exist_ok=True)\n",
        "print(\"\\nâœ… Dossiers crÃ©Ã©s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger le dataset Iris\n",
        "print(\"ğŸ“Š Chargement du dataset Iris...\")\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "print(f\"ğŸ“ˆ Forme des donnÃ©es: {X.shape}\")\n",
        "print(f\"ğŸ¯ Nombre de classes: {len(np.unique(y))}\")\n",
        "print(f\"ğŸ·ï¸ Classes: {iris.target_names}\")\n",
        "print(f\"ğŸ“‹ Features: {iris.feature_names}\")\n",
        "\n",
        "# Diviser en train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nğŸ“Š Division train/test:\")\n",
        "print(f\"   Train: {X_train.shape[0]} Ã©chantillons\")\n",
        "print(f\"   Test: {X_test.shape[0]} Ã©chantillons\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EntraÃ®ner le modÃ¨le\n",
        "print(\"ğŸ¤– EntraÃ®nement du modÃ¨le Random Forest...\")\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# PrÃ©dictions et Ã©valuation\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nğŸ“Š Performance du modÃ¨le:\")\n",
        "print(f\"   Accuracy: {accuracy:.4f}\")\n",
        "print(f\"   Classes: {iris.target_names}\")\n",
        "\n",
        "# Rapport de classification\n",
        "print(\"\\nğŸ“‹ Rapport de classification:\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation des donnÃ©es\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Distribution des classes\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.countplot(y=y_train)\n",
        "plt.title('Distribution des classes (Train)')\n",
        "plt.xlabel('Classe')\n",
        "plt.ylabel('Nombre d\\'Ã©chantillons')\n",
        "\n",
        "# CorrÃ©lation entre features\n",
        "plt.subplot(1, 3, 2)\n",
        "df_train = pd.DataFrame(X_train, columns=iris.feature_names)\n",
        "df_train['target'] = y_train\n",
        "sns.heatmap(df_train.corr(), annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Matrice de corrÃ©lation')\n",
        "\n",
        "# Importance des features\n",
        "plt.subplot(1, 3, 3)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': iris.feature_names,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=True)\n",
        "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
        "plt.title('Importance des features')\n",
        "plt.xlabel('Importance')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sauvegarder le modÃ¨le\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "# Sauvegarder le modÃ¨le scikit-learn\n",
        "model_path = 'models/iris_classifier.pkl'\n",
        "with open(model_path, 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "# Sauvegarder les mÃ©tadonnÃ©es\n",
        "model_metadata = {\n",
        "    'accuracy': float(accuracy),\n",
        "    'model_type': 'RandomForestClassifier',\n",
        "    'features': iris.feature_names,\n",
        "    'classes': iris.target_names.tolist(),\n",
        "    'n_estimators': model.n_estimators,\n",
        "    'training_date': datetime.now().isoformat(),\n",
        "    'dataset_size': {\n",
        "        'train': len(X_train),\n",
        "        'test': len(X_test),\n",
        "        'total': len(X)\n",
        "    }\n",
        "}\n",
        "\n",
        "import json\n",
        "metadata_path = 'models/model_metadata.json'\n",
        "with open(metadata_path, 'w') as f:\n",
        "    json.dump(model_metadata, f, indent=2)\n",
        "\n",
        "print(f\"âœ… ModÃ¨le sauvegardÃ©: {model_path}\")\n",
        "print(f\"âœ… MÃ©tadonnÃ©es sauvegardÃ©es: {metadata_path}\")\n",
        "print(\"\\nğŸ“‹ MÃ©tadonnÃ©es du modÃ¨le:\")\n",
        "for key, value in model_metadata.items():\n",
        "    print(f\"   {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ğŸ‰ RÃ©sumÃ© de l'exÃ©cution:\")\n",
        "print(f\"   ğŸ“Š Dataset: {X.shape[0]} Ã©chantillons, {X.shape[1]} features\")\n",
        "print(f\"   ğŸ¤– ModÃ¨le: Random Forest ({model.n_estimators} arbres)\")\n",
        "print(f\"   ğŸ“ˆ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"   ğŸ’¾ ModÃ¨le: {model_path}\")\n",
        "print(f\"   ğŸ“‹ MÃ©tadonnÃ©es: {metadata_path}\")\n",
        "\n",
        "print(\"\\nï¿½ï¿½ Prochaines Ã©tapes:\")\n",
        "print(\"   1. Convertir le modÃ¨le au format ONNX\")\n",
        "print(\"   2. DÃ©ployer le modÃ¨le sur Triton\")\n",
        "print(\"   3. Tester l'infÃ©rence en temps rÃ©el\")\n",
        "print(\"   4. Enregistrer dans le Model Registry\")\n",
        "\n",
        "print(\"\\nğŸ”§ Configuration du workbench:\")\n",
        "print(f\"   ğŸ“ Working Directory: {os.getcwd()}\")\n",
        "print(f\"   ğŸ·ï¸ Namespace: {os.getenv('NAMESPACE', 'unknown')}\")\n",
        "print(f\"   ğŸ‘¤ User: {os.getenv('USER', 'unknown')}\")\n",
        "print(f\"   ğŸ”— Base URL: /notebook/triton-demo/test-triton\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
