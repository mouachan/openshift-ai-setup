{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# �� Classification Iris avec Triton Inference Server\n",
        "\n",
        "Ce notebook démontre l'utilisation de NVIDIA Triton Inference Server pour déployer et servir un modèle de classification Iris.\n",
        "\n",
        "## Configuration de l'environnement\n",
        "- **Image**: `s2i-generic-data-science-notebook:2025.1`\n",
        "- **Namespace**: `triton-demo`\n",
        "- **User**: `mouachan`\n",
        "- **Base URL**: `/notebook/triton-demo/test-triton`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Configuration de l'environnement...\n",
            "📁 Répertoire de travail: /Users/mouchan/projects/openshift-ai-setup/demos/triton-example/notebooks\n",
            "👤 Utilisateur: mouchan\n",
            "🏷️ Namespace: unknown\n",
            "\n",
            "🔗 Configuration du workbench:\n",
            "   JUPYTER_IMAGE: Non configuré\n",
            "\n",
            "📊 Configuration Model Registry:\n",
            "   MODEL_REGISTRY_URL: Non configuré\n",
            "\n",
            "☁️ Configuration S3/MinIO:\n",
            "   AWS_ACCESS_KEY_ID: Non configuré\n",
            "   AWS_S3_ENDPOINT: Non configuré\n",
            "   AWS_S3_BUCKET: Non configuré\n",
            "\n",
            "✅ Dossiers créés\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"🔧 Configuration de l'environnement...\")\n",
        "print(f\"📁 Répertoire de travail: {os.getcwd()}\")\n",
        "print(f\"👤 Utilisateur: {os.getenv('USER', 'unknown')}\")\n",
        "print(f\"🏷️ Namespace: {os.getenv('NAMESPACE', 'unknown')}\")\n",
        "\n",
        "# Variables d'environnement du workbench\n",
        "print(f\"\\n🔗 Configuration du workbench:\")\n",
        "print(f\"   JUPYTER_IMAGE: {os.getenv('JUPYTER_IMAGE', 'Non configuré')}\")\n",
        "\n",
        "# Variables Model Registry et S3\n",
        "print(f\"\\n📊 Configuration Model Registry:\")\n",
        "print(f\"   MODEL_REGISTRY_URL: {os.getenv('MODEL_REGISTRY_URL', 'Non configuré')}\")\n",
        "\n",
        "print(f\"\\n☁️ Configuration S3/MinIO:\")\n",
        "print(f\"   AWS_ACCESS_KEY_ID: {os.getenv('AWS_ACCESS_KEY_ID', 'Non configuré')}\")\n",
        "print(f\"   AWS_S3_ENDPOINT: {os.getenv('AWS_S3_ENDPOINT', 'Non configuré')}\")\n",
        "print(f\"   AWS_S3_BUCKET: {os.getenv('AWS_S3_BUCKET', 'Non configuré')}\")\n",
        "\n",
        "# Créer les dossiers nécessaires\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('data', exist_ok=True)\n",
        "print(\"\\n✅ Dossiers créés\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger le dataset Iris\n",
        "print(\"📊 Chargement du dataset Iris...\")\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "print(f\"📈 Forme des données: {X.shape}\")\n",
        "print(f\"🎯 Nombre de classes: {len(np.unique(y))}\")\n",
        "print(f\"🏷️ Classes: {iris.target_names}\")\n",
        "print(f\"📋 Features: {iris.feature_names}\")\n",
        "\n",
        "# Diviser en train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\n📊 Division train/test:\")\n",
        "print(f\"   Train: {X_train.shape[0]} échantillons\")\n",
        "print(f\"   Test: {X_test.shape[0]} échantillons\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entraîner le modèle\n",
        "print(\"🤖 Entraînement du modèle Random Forest...\")\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prédictions et évaluation\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n📊 Performance du modèle:\")\n",
        "print(f\"   Accuracy: {accuracy:.4f}\")\n",
        "print(f\"   Classes: {iris.target_names}\")\n",
        "\n",
        "# Rapport de classification\n",
        "print(\"\\n📋 Rapport de classification:\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation des données\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Distribution des classes\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.countplot(y=y_train)\n",
        "plt.title('Distribution des classes (Train)')\n",
        "plt.xlabel('Classe')\n",
        "plt.ylabel('Nombre d\\'échantillons')\n",
        "\n",
        "# Corrélation entre features\n",
        "plt.subplot(1, 3, 2)\n",
        "df_train = pd.DataFrame(X_train, columns=iris.feature_names)\n",
        "df_train['target'] = y_train\n",
        "sns.heatmap(df_train.corr(), annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Matrice de corrélation')\n",
        "\n",
        "# Importance des features\n",
        "plt.subplot(1, 3, 3)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': iris.feature_names,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=True)\n",
        "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
        "plt.title('Importance des features')\n",
        "plt.xlabel('Importance')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sauvegarder le modèle\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "# Sauvegarder le modèle scikit-learn\n",
        "model_path = 'models/iris_classifier.pkl'\n",
        "with open(model_path, 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "# Sauvegarder les métadonnées\n",
        "model_metadata = {\n",
        "    'accuracy': float(accuracy),\n",
        "    'model_type': 'RandomForestClassifier',\n",
        "    'features': iris.feature_names,\n",
        "    'classes': iris.target_names.tolist(),\n",
        "    'n_estimators': model.n_estimators,\n",
        "    'training_date': datetime.now().isoformat(),\n",
        "    'dataset_size': {\n",
        "        'train': len(X_train),\n",
        "        'test': len(X_test),\n",
        "        'total': len(X)\n",
        "    }\n",
        "}\n",
        "\n",
        "import json\n",
        "metadata_path = 'models/model_metadata.json'\n",
        "with open(metadata_path, 'w') as f:\n",
        "    json.dump(model_metadata, f, indent=2)\n",
        "\n",
        "print(f\"✅ Modèle sauvegardé: {model_path}\")\n",
        "print(f\"✅ Métadonnées sauvegardées: {metadata_path}\")\n",
        "print(\"\\n📋 Métadonnées du modèle:\")\n",
        "for key, value in model_metadata.items():\n",
        "    print(f\"   {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"🎉 Résumé de l'exécution:\")\n",
        "print(f\"   📊 Dataset: {X.shape[0]} échantillons, {X.shape[1]} features\")\n",
        "print(f\"   🤖 Modèle: Random Forest ({model.n_estimators} arbres)\")\n",
        "print(f\"   📈 Accuracy: {accuracy:.4f}\")\n",
        "print(f\"   💾 Modèle: {model_path}\")\n",
        "print(f\"   📋 Métadonnées: {metadata_path}\")\n",
        "\n",
        "print(\"\\n�� Prochaines étapes:\")\n",
        "print(\"   1. Convertir le modèle au format ONNX\")\n",
        "print(\"   2. Déployer le modèle sur Triton\")\n",
        "print(\"   3. Tester l'inférence en temps réel\")\n",
        "print(\"   4. Enregistrer dans le Model Registry\")\n",
        "\n",
        "print(\"\\n🔧 Configuration du workbench:\")\n",
        "print(f\"   📁 Working Directory: {os.getcwd()}\")\n",
        "print(f\"   🏷️ Namespace: {os.getenv('NAMESPACE', 'unknown')}\")\n",
        "print(f\"   👤 User: {os.getenv('USER', 'unknown')}\")\n",
        "print(f\"   🔗 Base URL: /notebook/triton-demo/test-triton\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
