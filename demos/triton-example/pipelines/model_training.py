#!/usr/bin/env python3
"""
Ã‰tape 2: Model Training
EntraÃ®nement d'un modÃ¨le de classification Iris et export pour Triton
"""

import numpy as np
import pickle
import os
import argparse
import tensorflow as tf
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

def train_model(data_path: str = "/tmp/data", model_path: str = "/tmp/model"):
    """EntraÃ®nement du modÃ¨le et export au format TensorFlow SavedModel pour Triton"""
    
    print("ğŸ”„ Chargement des donnÃ©es preprocessÃ©es...")
    
    # Charger les donnÃ©es
    X_train = np.load(f"{data_path}/X_train.npy")
    X_test = np.load(f"{data_path}/X_test.npy")
    y_train = np.load(f"{data_path}/y_train.npy")
    y_test = np.load(f"{data_path}/y_test.npy")
    
    with open(f"{data_path}/metadata.pkl", "rb") as f:
        metadata = pickle.load(f)
    
    print(f"ğŸ“Š Train set: {X_train.shape}")
    print(f"ğŸ“Š Test set: {X_test.shape}")
    print(f"ğŸ“Š Features: {metadata['feature_names']}")
    print(f"ğŸ“Š Classes: {metadata['target_names']}")
    
    print("ğŸ”„ EntraÃ®nement du modÃ¨le Random Forest...")
    
    # EntraÃ®ner un modÃ¨le Random Forest
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    print("ğŸ”„ Ã‰valuation du modÃ¨le...")
    
    # PrÃ©dictions et Ã©valuation
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"ğŸ¯ Accuracy: {accuracy:.4f}")
    print("ğŸ“Š Classification Report:")
    print(classification_report(y_test, y_pred, target_names=metadata['target_names']))
    
    print("ğŸ”„ Export du modÃ¨le au format TensorFlow SavedModel pour Triton...")
    
    # CrÃ©er le rÃ©pertoire de sortie pour Triton
    triton_model_path = f"{model_path}/iris_classifier/1"
    os.makedirs(triton_model_path, exist_ok=True)
    
    # CrÃ©er un wrapper TensorFlow pour le modÃ¨le scikit-learn
    class IrisClassifierWrapper(tf.Module):
        def __init__(self, sklearn_model, scaler):
            super().__init__()
            self.sklearn_model = sklearn_model
            self.scaler = scaler
            
        @tf.function(input_signature=[tf.TensorSpec(shape=[None, 4], dtype=tf.float32)])
        def __call__(self, x):
            # Normaliser les inputs
            x_scaled = tf.py_function(
                lambda x: self.scaler.transform(x.numpy()).astype(np.float32),
                [x], tf.float32
            )
            x_scaled.set_shape([None, 4])
            
            # PrÃ©diction
            predictions = tf.py_function(
                lambda x: self.sklearn_model.predict_proba(x.numpy()).astype(np.float32),
                [x_scaled], tf.float32
            )
            predictions.set_shape([None, 3])
            
            return {"probabilities": predictions}
    
    # Charger le scaler
    with open(f"{data_path}/scaler.pkl", "rb") as f:
        scaler = pickle.load(f)
    
    # CrÃ©er le wrapper
    wrapper = IrisClassifierWrapper(model, scaler)
    
    # Sauvegarder au format TensorFlow SavedModel
    tf.saved_model.save(wrapper, triton_model_path)
    
    print(f"ğŸ’¾ ModÃ¨le sauvegardÃ© dans {triton_model_path}")
    
    # CrÃ©er le fichier de configuration Triton
    config_content = f'''name: "iris_classifier"
platform: "tensorflow_savedmodel"
max_batch_size: 8
input [
  {{
    name: "x"
    data_type: TYPE_FP32
    dims: [ 4 ]
  }}
]
output [
  {{
    name: "probabilities"
    data_type: TYPE_FP32
    dims: [ 3 ]
  }}
]
version_policy: {{ all: {{}} }}
'''
    
    with open(f"{model_path}/iris_classifier/config.pbtxt", "w") as f:
        f.write(config_content)
    
    print("ğŸ“ Configuration Triton crÃ©Ã©e")
    
    # Sauvegarder les mÃ©triques du modÃ¨le
    metrics = {
        "accuracy": float(accuracy),
        "model_type": "RandomForestClassifier",
        "n_estimators": 100,
        "features": metadata['feature_names'],
        "classes": metadata['target_names'],
        "triton_model_path": triton_model_path
    }
    
    with open(f"{model_path}/metrics.pkl", "wb") as f:
        pickle.dump(metrics, f)
    
    print("âœ… EntraÃ®nement et export terminÃ©s avec succÃ¨s!")
    
    return model_path

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data-path", default="/tmp/data", help="Chemin des donnÃ©es preprocessÃ©es")
    parser.add_argument("--model-path", default="/tmp/model", help="Chemin de sortie du modÃ¨le")
    args = parser.parse_args()
    
    train_model(args.data_path, args.model_path)
