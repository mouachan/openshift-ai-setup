# Template Seldon MLServer Runtime
# Bas√© sur le chapitre 2.11.3 de la documentation OpenShift AI 2.22
# Template pour affichage dans l'interface OpenShift AI
apiVersion: template.openshift.io/v1
kind: Template
metadata:
  name: seldon-mlserver-runtime-template
  namespace: redhat-ods-applications
  labels:
    app.kubernetes.io/name: seldon-mlserver-runtime
    app.kubernetes.io/component: serving-runtime
    app.kubernetes.io/part-of: openshift-ai
    app.kubernetes.io/instance: openshift-ai-complete
    app.kubernetes.io/managed-by: kustomize
    app.kubernetes.io/version: "2.22"
    environment: development
    opendatahub.io/dashboard: "true"
    opendatahub.io/ootb: "true"
  annotations:
    description: "Seldon MLServer - Multi-framework ML serving runtime"
    openshift.io/display-name: "Seldon MLServer Runtime"
    openshift.io/provider-display-name: "Seldon Technologies"
    tags: "seldon,mlserver,sklearn,xgboost,lightgbm,mlflow,huggingface,ai,ml,servingruntime"
    opendatahub.io/apiProtocol: "REST"
    opendatahub.io/modelServingSupport: '["multi"]'
objects:
- apiVersion: serving.kserve.io/v1alpha1
  kind: ServingRuntime
  metadata:
    name: seldon-mlserver-runtime
    labels:
      app.kubernetes.io/name: seldon-mlserver-runtime
      app.kubernetes.io/component: serving-runtime
      app.kubernetes.io/part-of: openshift-ai
      runtime: seldon-mlserver
  spec:
    annotations:
      prometheus.kserve.io/path: "/metrics"
      prometheus.kserve.io/port: "8080"
      serving.kserve.io/enable-prometheus-scraping: "true"
      serving.kserve.io/enable-route: "true"
    multiModel: true
    supportedModelFormats:
    # scikit-learn models
    - name: sklearn
      version: "1"
      autoSelect: true
    # XGBoost models
    - name: xgboost
      version: "1"
      autoSelect: true
    # LightGBM models
    - name: lightgbm
      version: "3"
      autoSelect: true
    # MLflow models
    - name: mlflow
      version: "1"
      autoSelect: true
    # Hugging Face models
    - name: huggingface
      version: "1"
      autoSelect: true
    # Tempo models (Seldon native)
    - name: tempo
      version: "1"
      autoSelect: true
    containers:
    - name: mlserver
      image: seldonio/mlserver:1.3.5
      env:
      - name: MLSERVER_MODEL_IMPLEMENTATION
        value: "mlserver_sklearn.SKLearnModel"
      - name: MLSERVER_HTTP_PORT
        value: "8080"
      - name: MLSERVER_GRPC_PORT
        value: "8081"
      - name: MLSERVER_METRICS_PORT
        value: "8082"
      - name: MLSERVER_LOAD_MODELS_AT_STARTUP
        value: "false"
      - name: MLSERVER_MODEL_NAME
        value: "model"
      - name: MLSERVER_MODEL_URI
        value: "/mnt/models"
      - name: MLSERVER_PARALLEL_WORKERS
        value: "1"
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      - containerPort: 8081
        name: grpc
        protocol: TCP
      - containerPort: 8082
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 500m
          memory: 1Gi
        limits:
          cpu: "2"
          memory: 4Gi
      volumeMounts:
      - name: model-dir
        mountPath: /mnt/models
      livenessProbe:
        httpGet:
          path: /v2/health/live
          port: 8080
        initialDelaySeconds: 30
        periodSeconds: 30
        timeoutSeconds: 10
      readinessProbe:
        httpGet:
          path: /v2/health/ready
          port: 8080
        initialDelaySeconds: 10
        periodSeconds: 30
        timeoutSeconds: 10
    volumes:
    - name: model-dir
      emptyDir: {}
    builtInAdapter:
      serverType: mlserver
      runtimeManagementPort: 8081
      memBufferBytes: 134217728
      modelLoadingTimeoutMillis: 90000
