apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: iris-classifier-triton
  namespace: triton-demo
  labels:
    app.kubernetes.io/name: iris-classifier-triton
    app.kubernetes.io/component: inference-service
    app.kubernetes.io/part-of: openshift-ai-demo
    app.kubernetes.io/managed-by: gitops
    demo.openshift.ai/type: triton-inference
    opendatahub.io/dashboard: 'true'
  annotations:
    openshift.io/display-name: "Iris Classifier - Triton"
    openshift.io/description: "Service d'inf√©rence pour la classification Iris avec Triton"
    serving.kserve.io/deploymentMode: ModelMesh
spec:
  predictor:
    automountServiceAccountToken: false
    model:
      modelFormat:
        name: tensorflow
        version: '2'
      name: ''
      resources: {}
      runtime: nvidia-triton-runtime
      storage:
        key: triton-demo-s3-connection
        path: iris-classifier/1
