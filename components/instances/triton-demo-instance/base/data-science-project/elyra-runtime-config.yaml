apiVersion: v1
kind: ConfigMap
metadata:
  name: elyra-runtime-config
  namespace: triton-demo
  labels:
    app.kubernetes.io/name: elyra-runtime-config
    app.kubernetes.io/part-of: triton-demo
data:
  # Configuration des runtime images pour Elyra
  runtime-images.yaml: |
    # Configuration des images disponibles pour les composants de pipeline
    # Ces images appara√Ætront dans le dropdown "Runtime Image" des pipelines
    runtime_images:
      - display_name: "Triton Demo - Custom ML/AI Image"
        image_name: "image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/triton-demo-notebook:latest"
        description: "Image personnalis√©e avec NumPy, Pandas, Scikit-learn, Triton Client et toutes les biblioth√®ques ML/AI pr√©-install√©es"
        tags: ["ml", "ai", "triton", "custom", "python3.11"]
        metadata:
          gpu: false
          cuda: false
          python_version: "3.11"
          packages:
            - "NumPy 2.3+"
            - "Pandas 2.3+"
            - "Scikit-learn 1.7+"
            - "Triton Client 2.59+"
            - "Kubeflow Pipelines 1.8+"
            - "Elyra 3.15.0"
      
      - display_name: "Standard Data Science (Fallback)"
        image_name: "quay.io/opendatahub/workbench-images:jupyter-datascience-ubi9-python-3.11-2024a-20240317-6f4c36b"
        description: "Image standard OpenShift AI pour compatibilit√©"
        tags: ["standard", "fallback", "python3.11"]
        metadata:
          gpu: false
          cuda: false
          python_version: "3.11"

  # Script d'initialisation du runtime bas√© sur le script officiel OpenShift AI
  init-runtime.py: |
    #!/usr/bin/env python3
    """
    Script pour configurer automatiquement le runtime Elyra
    Bas√© sur la m√©thode officielle OpenShift AI
    """
    import os
    import json
    import yaml
    from pathlib import Path

    # Configuration bas√©e sur le mod√®le Data Science Project
    ELYRA_METADATA_DIR = os.path.expanduser("~/.local/share/jupyter/metadata")
    NAMESPACE = "triton-demo"
    CLUSTER_DOMAIN = "apps.cluster-v2mx6.v2mx6.sandbox1062.opentlc.com"

    def ensure_elyra_dirs():
        """Cr√©e les r√©pertoires Elyra n√©cessaires"""
        dirs = [
            f"{ELYRA_METADATA_DIR}/runtimes",
            f"{ELYRA_METADATA_DIR}/component-catalogs",
            f"{ELYRA_METADATA_DIR}/code-snippets",
            f"{ELYRA_METADATA_DIR}/runtime-images",
        ]
        
        for dir_path in dirs:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
            print(f"‚úì R√©pertoire cr√©√©: {dir_path}")

    def create_kubeflow_runtime():
        """Cr√©e la configuration runtime Kubeflow Pipelines comme OpenShift AI"""
        return {
            "display_name": "Data Science Pipelines (Triton Demo)",
            "metadata": {
                "api_endpoint": f"https://ds-pipeline-triton-demo-pipelines-{NAMESPACE}.{CLUSTER_DOMAIN}",
                "api_username": "",
                "api_password": "",
                "cos_endpoint": f"http://minio-api-minio.{NAMESPACE}.svc:9000",
                "cos_username": "minioadmin",
                "cos_password": "minioadmin",
                "cos_bucket": "triton-data",
                "cos_directory": "",
                "tags": ["kubeflow", "pipelines", "triton", "custom-image"],
                "engine": "Argo",
                "auth_type": "NO_AUTHENTICATION",
                "runtime_type": "KUBEFLOW_PIPELINES",
                "api_version": "v1",
                "user_namespace": NAMESPACE,
                "engine_namespace": NAMESPACE,
                "cos_secure": False,
                "disable_ssl_verification": True,
                "cos_auth_type": "USER_CREDENTIALS"
            },
            "schema_name": "kfp",
            "name": "data_science_pipelines"
        }

    def create_runtime_images():
        """Cr√©e la configuration des runtime images disponibles"""
        return [
            {
                "display_name": "Triton Demo - Custom ML/AI Image",
                "image_name": "image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/triton-demo-notebook:latest",
                "description": "Image personnalis√©e avec NumPy, Pandas, Scikit-learn, Triton Client et toutes les biblioth√®ques ML/AI pr√©-install√©es",
                "tags": ["ml", "ai", "triton", "custom", "python3.11"],
                "metadata": {
                    "gpu": False,
                    "cuda": False,
                    "python_version": "3.11",
                    "packages": [
                        "NumPy 2.3+",
                        "Pandas 2.3+",
                        "Scikit-learn 1.7+",
                        "Triton Client 2.59+",
                        "Kubeflow Pipelines 1.8+",
                        "Elyra 3.15.0"
                    ]
                }
            },
            {
                "display_name": "Standard Data Science (Fallback)",
                "image_name": "quay.io/opendatahub/workbench-images:jupyter-datascience-ubi9-python-3.11-2024a-20240317-6f4c36b",
                "description": "Image standard OpenShift AI pour compatibilit√©",
                "tags": ["standard", "fallback", "python3.11"],
                "metadata": {
                    "gpu": False,
                    "cuda": False,
                    "python_version": "3.11"
                }
            }
        ]

    def save_metadata(metadata, file_path):
        """Sauvegarde les m√©tadonn√©es dans un fichier JSON"""
        try:
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            print(f"‚úì Runtime configur√©: {file_path}")
            return True
        except Exception as e:
            print(f"‚úó Erreur lors de la sauvegarde {file_path}: {e}")
            return False

    def save_runtime_images(runtime_images):
        """Sauvegarde la configuration des runtime images"""
        try:
            runtime_images_dir = f"{ELYRA_METADATA_DIR}/runtime-images"
            os.makedirs(runtime_images_dir, exist_ok=True)
            
            # Sauvegarder chaque runtime image dans un fichier s√©par√©
            for i, runtime_image in enumerate(runtime_images):
                file_path = f"{runtime_images_dir}/runtime_image_{i+1}.json"
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(runtime_image, f, indent=2, ensure_ascii=False)
                print(f"‚úì Runtime image configur√©: {file_path}")
            
            # Sauvegarder aussi dans un fichier principal
            main_file = f"{runtime_images_dir}/runtime_images.json"
            with open(main_file, 'w', encoding='utf-8') as f:
                json.dump({"runtime_images": runtime_images}, f, indent=2, ensure_ascii=False)
            print(f"‚úì Configuration principale des runtime images: {main_file}")
            
            return True
        except Exception as e:
            print(f"‚úó Erreur lors de la sauvegarde des runtime images: {e}")
            return False

    def main():
        """Configuration principale du runtime comme OpenShift AI"""
        print("üîß Configuration automatique du runtime Elyra (m√©thode OpenShift AI)")
        print("=" * 70)
        
        # Cr√©er les r√©pertoires n√©cessaires
        ensure_elyra_dirs()
        
        # Cr√©er le runtime Kubeflow comme OpenShift AI
        runtime_config = create_kubeflow_runtime()
        
        # Cr√©er les runtime images
        runtime_images = create_runtime_images()
        
        # Sauvegarder le runtime dans le bon r√©pertoire
        runtime_file = f"{ELYRA_METADATA_DIR}/runtimes/data_science_pipelines.json"
        
        if save_metadata(runtime_config, runtime_file):
            print("\n‚úÖ Configuration du runtime termin√©e avec succ√®s!")
            print(f"üìÅ Fichier: {runtime_file}")
            print(f"üîó Endpoint: {runtime_config['metadata']['api_endpoint']}")
            print(f"üì¶ Bucket S3: {runtime_config['metadata']['cos_bucket']}")
            print(f"üè∑Ô∏è Nom du runtime: {runtime_config['display_name']}")
            print(f"‚öôÔ∏è Engine: {runtime_config['metadata']['engine']}")
            print(f"üîê Auth Type: {runtime_config['metadata']['auth_type']}")
        
        # Sauvegarder les runtime images
        if save_runtime_images(runtime_images):
            print("\n‚úÖ Configuration des runtime images termin√©e avec succ√®s!")
            print(f"üì¶ Nombre d'images configur√©es: {len(runtime_images)}")
            for img in runtime_images:
                print(f"  - {img['display_name']}: {img['image_name']}")
        
        # Configuration de l'authentification Kubernetes
        setup_kubernetes_auth()
        
        # V√©rifier que les fichiers existent
        if os.path.exists(runtime_file):
            print("‚úÖ Le runtime est pr√™t √† √™tre utilis√© dans Elyra!")
        else:
            print("‚ùå Erreur: Le fichier de runtime n'a pas √©t√© cr√©√©")
            
        runtime_images_dir = f"{ELYRA_METADATA_DIR}/runtime-images"
        if os.path.exists(runtime_images_dir):
            print("‚úÖ Les runtime images sont pr√™tes √† √™tre utilis√©es dans les pipelines!")
        else:
            print("‚ùå Erreur: Le r√©pertoire des runtime images n'a pas √©t√© cr√©√©")

    def setup_kubernetes_auth():
        """Configure l'authentification Kubernetes pour les pipelines"""
        print("\nüîê Configuration de l'authentification Kubernetes...")
        
        # V√©rifier la pr√©sence du token de service account
        token_path = "/var/run/secrets/kubernetes.io/serviceaccount/token"
        if os.path.exists(token_path):
            print("‚úÖ Token de service account trouv√©")
            try:
                with open(token_path, 'r') as f:
                    token = f.read().strip()
                    print(f"‚úÖ Token charg√© (longueur: {len(token)} caract√®res)")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lors de la lecture du token: {e}")
        else:
            print("‚ö†Ô∏è Token de service account non trouv√©")
            
        # V√©rifier les variables d'environnement Kubernetes
        k8s_host = os.environ.get('KUBERNETES_SERVICE_HOST', 'kubernetes.default.svc')
        k8s_port = os.environ.get('KUBERNETES_SERVICE_PORT', '443')
        print(f"‚úÖ API Kubernetes: https://{k8s_host}:{k8s_port}")
        
        namespace_path = "/var/run/secrets/kubernetes.io/serviceaccount/namespace"
        if os.path.exists(namespace_path):
            try:
                with open(namespace_path, 'r') as f:
                    namespace = f.read().strip()
                    print(f"‚úÖ Namespace: {namespace}")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lors de la lecture du namespace: {e}")
        else:
                print(f"‚úÖ Namespace configur√©: {NAMESPACE}")
            
        print("‚úÖ Configuration d'authentification termin√©e")

    if __name__ == "__main__":
        main()

  # Configuration Elyra avanc√©e
  jupyter_elyra_config.py: |
    # Configuration Elyra pour les pipelines
    c.ElyraApp.enable_pipeline_editing = True
    c.ElyraApp.runtime_env = 'kubeflow_pipelines'
    
    # Configuration des data connections
    c.ElyraApp.data_connections = {
        'triton-data-connection': {
            'type': 's3',
            'endpoint': 'http://minio-api-minio.svc:9000',
            'access_key': 'minioadmin',
            'secret_key': 'minioadmin',
            'bucket': 'triton-data'
        }
    }
    
    # Configuration des runtime images
    c.ElyraApp.runtime_images = [
        {
            'display_name': 'Triton Demo - Custom ML/AI Image',
            'image_name': 'image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/triton-demo-notebook:latest',
            'description': 'Image personnalis√©e avec toutes les biblioth√®ques ML/AI pr√©-install√©es',
            'tags': ['ml', 'ai', 'triton', 'custom', 'python3.11']
        },
        {
            'display_name': 'Standard Data Science (Fallback)',
            'image_name': 'quay.io/opendatahub/workbench-images:jupyter-datascience-ubi9-python-3.11-2024a-20240317-6f4c36b',
            'description': 'Image standard OpenShift AI pour compatibilit√©',
            'tags': ['standard', 'fallback', 'python3.11']
        }
    ] 