# üöÄ Guide de D√©marrage Rapide - OpenShift AI Setup

> **D√©marrage en 5 minutes pour OpenShift AI avec workbench personnalis√© et pipelines**

## ‚ö° **Installation Express (5 minutes)**

### **1. Pr√©requis**
```bash
# V√©rifier OpenShift CLI
oc version

# V√©rifier l'acc√®s au cluster
oc whoami

# V√©rifier les droits administrateur
oc auth can-i create datascienceclusters --all-namespaces
```

### **2. Installation en une commande**
```bash
# Cloner et installer
git clone https://github.com/votre-org/openshift-ai-setup.git
cd openshift-ai-setup
./install.sh
```

### **3. V√©rification rapide**
```bash
# V√©rifier que tout fonctionne
oc get pods -A | grep -E "(triton|minio|model-registry)"
```

## üîß **Installation Manuelle (10 minutes)**

### **√âtape 1 : Op√©rateurs**
```bash
# Installer tous les op√©rateurs n√©cessaires
oc apply -k components/operators/

# Attendre que les op√©rateurs soient pr√™ts
oc get csv -A | grep -E "(rhods|servicemesh|serverless)"
```

### **√âtape 2 : Infrastructure de base**
```bash
# MinIO pour le stockage
oc apply -k components/instances/minio-instance/base/

# Model Registry
oc apply -k components/instances/rhoai-instance/components/model-registry/

# Serving Runtimes personnalis√©s
oc apply -k components/instances/rhoai-instance/components/custom-serving-runtimes/
```

### **√âtape 3 : Workbench personnalis√©**
```bash
# D√©ployer le workbench avec image personnalis√©e
oc apply -k components/instances/triton-demo-instance/base/data-science-project/

# Attendre que le workbench d√©marre
oc get pods -n triton-demo -w
```

### **√âtape 4 : Configuration Elyra**
```bash
# Appliquer la configuration Elyra
oc apply -f components/instances/triton-demo-instance/base/data-science-project/elyra-runtime-config.yaml

# Configurer le runtime dans le workbench
oc exec triton-workbench-0 -n triton-demo -c triton-workbench -- python3 /opt/app-root/elyra-config/init-runtime.py
```

### **√âtape 5 : GitOps (optionnel)**
```bash
# Configurer ArgoCD pour la synchronisation automatique
oc apply -k argocd-apps/
```

## üéØ **Premiers Pas**

### **Acc√©der au workbench**
1. **Ouvrir la route** : `triton-workbench-triton-demo.apps.<cluster>.opentlc.com`
2. **Se connecter** avec vos credentials OpenShift
3. **V√©rifier Elyra** : L'extension devrait √™tre visible dans JupyterLab

### **Cr√©er votre premier pipeline**
1. **Ouvrir Elyra** dans JupyterLab
2. **Cr√©er un pipeline** : `File > New > Pipeline`
3. **S√©lectionner le runtime** : "Data Science Pipelines (OpenShift AI)"
4. **Ajouter des composants** et connecter
5. **Ex√©cuter le pipeline**

### **Utiliser l'image personnalis√©e**
1. **Ouvrir un notebook** : `File > New > Notebook`
2. **S√©lectionner l'image** : "Triton Demo - Custom ML/AI Image"
3. **V√©rifier les biblioth√®ques** :
   ```python
   import torch
   import langchain
   import ultralytics
   print("‚úÖ Toutes les biblioth√®ques sont disponibles!")
   ```

## üîç **V√©rification de l'Installation**

### **Checklist de validation**
```bash
# ‚úÖ Workbench fonctionnel
oc get pods -n triton-demo | grep Running

# ‚úÖ MinIO accessible
oc get routes -n minio

# ‚úÖ Model Registry configur√©
oc get pods -n rhoai-model-registries

# ‚úÖ Pipelines disponibles
oc get datasciencepipelinesapplications -A

# ‚úÖ Images personnalis√©es
oc get imagestreams -n redhat-ods-applications | grep triton
```

### **Test de connectivit√©**
```bash
# Tester l'API des pipelines
curl -k "https://ds-pipeline-dspa-test-pipeline.apps.<cluster>/api/v1/healthz"

# Tester MinIO
curl -k "https://minio-api-minio.apps.<cluster>/health/live"
```

## üö® **D√©pannage Rapide**

### **Workbench ne d√©marre pas**
```bash
# V√©rifier les ressources
oc describe pod triton-workbench-0 -n triton-demo

# V√©rifier les logs
oc logs triton-workbench-0 -n triton-demo -c triton-workbench

# Red√©marrer si n√©cessaire
oc delete notebook triton-workbench -n triton-demo
oc apply -f components/instances/triton-demo-instance/base/data-science-project/workbench.yaml
```

### **Erreur d'authentification pipeline**
```bash
# V√©rifier la configuration Elyra
oc exec triton-workbench-0 -n triton-demo -c triton-workbench -- cat /opt/app-root/src/.local/share/jupyter/metadata/runtimes/data_science_pipelines.json

# Reconfigurer si n√©cessaire
oc exec triton-workbench-0 -n triton-demo -c triton-workbench -- python3 /opt/app-root/elyra-config/init-runtime.py
```

### **MinIO inaccessible**
```bash
# V√©rifier le service
oc get svc -n minio

# V√©rifier les routes
oc get routes -n minIO

# V√©rifier les pods
oc get pods -n minio
```

## üìö **Prochaines √âtapes**

### **D√©veloppement de pipelines**
- [Guide des pipelines Elyra](https://elyra.readthedocs.io/)
- [Exemples de pipelines](demos/triton-example/pipelines/)
- [Documentation Kubeflow](https://www.kubeflow.org/)

### **D√©ploiement de mod√®les**
- [Guide du Model Registry](docs/CUSTOM-NOTEBOOK-IMAGE.md)
- [Serving avec Triton](components/instances/rhoai-instance/components/custom-serving-runtimes/README.md)
- [Documentation Seldon](https://docs.seldon.io/)

### **Personnalisation avanc√©e**
- [Architecture modulaire](docs/MODULAR-ARCHITECTURE.md)
- [Configuration des images](docs/CUSTOM-NOTEBOOK-IMAGE.md)
- [Gestion GitOps](argocd-apps/)

## üéâ **F√©licitations !**

Votre setup OpenShift AI est maintenant **100% fonctionnel** avec :
- ‚úÖ **Workbench personnalis√©** avec biblioth√®ques ML/AI
- ‚úÖ **Pipelines Elyra** fonctionnels
- ‚úÖ **Infrastructure compl√®te** (MinIO, Model Registry, Serving)
- ‚úÖ **GitOps** configur√© pour la maintenance

**Vous √™tes pr√™t √† d√©velopper et d√©ployer des solutions ML/AI en production !** üöÄ

---

## üìû **Besoin d'aide ?**

- **Documentation compl√®te** : [README.md](../README.md)
- **Issues GitHub** : [Cr√©er une issue](https://github.com/votre-org/openshift-ai-setup/issues)
- **Scripts de diagnostic** : [scripts/](../scripts/)
